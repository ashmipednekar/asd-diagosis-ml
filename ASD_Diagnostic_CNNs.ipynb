{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashmipednekar/asd-diagosis-ml/blob/main/ASD_Diagnostic_CNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kc-fGmYyuXC6"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6CdQxS2uOa1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "import random\n",
        "import torch.nn as nn\n",
        "from torch.optim import *\n",
        "import os\n",
        "import zipfile\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEBPMXrluf3H"
      },
      "source": [
        "# Mounting Drive\n",
        "\n",
        "**NOTE**: Please replace this path with the correct path to your Google Drive and your raw data path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1ShrCWtuZpK",
        "outputId": "f040306d-afb0-44a8-c512-41aab5abe527"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4se5k0FSE0yc"
      },
      "outputs": [],
      "source": [
        "zip_ref = zipfile.ZipFile('/content/drive/MyDrive/FMRIScans.zip', 'r')\n",
        "zip_ref.extractall('/FMRIScans')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZ7z9qrMupHZ"
      },
      "outputs": [],
      "source": [
        "fmri_scans_path = Path('/FMRIScans/FMRIScans')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV3GGj72wNpg"
      },
      "source": [
        "# Other Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkGKB3LGwSMw"
      },
      "source": [
        "## Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7-DrAmQGnYa"
      },
      "outputs": [],
      "source": [
        "# We define a general FMRI Scans Dataset class\n",
        "class FMRIScansData(torch.utils.data.Dataset):\n",
        "    def __init__(self, path_list):\n",
        "        self.path_list = path_list\n",
        "        self.to_tensor = ToTensor()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.path_list)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # Get the image data folder path\n",
        "        image_path = self.path_list[idx]\n",
        "        # Load and setup the image\n",
        "        all_img_files = [x for x in image_path.iterdir() if x.name not in ['.DS_Store']]\n",
        "        \n",
        "        # Now, we assume that z is 0 to 60 (dim of 61), t is 0 to 75, going up by 5 each time (dim of 16)\n",
        "        full_img = []\n",
        "        for t in range(0, 80, 5):\n",
        "            curr_img = []\n",
        "\n",
        "            for z in range(0, 61):\n",
        "                # We first double check to make sure that it loads correctly\n",
        "                partial_img_path = image_path / f'{image_path.name}_{z}_{t}.png'\n",
        "                if partial_img_path not in all_img_files:\n",
        "                    raise Exception(f\"TING: {partial_img_path}\")\n",
        "                \n",
        "                # We added all of the 3D slices of the brain image together\n",
        "                partial_img = Image.open(partial_img_path)\n",
        "                curr_img += [self.to_tensor(partial_img)]\n",
        "\n",
        "            # We make it a stack\n",
        "            full_img += [torch.stack(curr_img)]\n",
        "        \n",
        "        # We stack them all up and return\n",
        "        full_img = torch.stack(full_img)\n",
        "        full_img = full_img.reshape(16, 61, 61, 73)\n",
        "        # Check whether subject has ASD class or Control class and set label\n",
        "        label = 0.0 if 'Control/' in str(image_path) else 1.0\n",
        "        return full_img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46o1Yqu7D2OI"
      },
      "outputs": [],
      "source": [
        "# Then, get all ASD sample filepaths, and all Control sample filepaths, to load them up\n",
        "asd_files = list((fmri_scans_path / 'ASD').iterdir())\n",
        "control_files = list((fmri_scans_path / 'Control').iterdir())\n",
        "\n",
        "# We combine all of these, and then create an 80/20 training testing split, setting a seed value\n",
        "random.seed(314)\n",
        "total_files = asd_files + control_files\n",
        "total_files = [x for x in total_files if x.name not in ['.DS_Store']]\n",
        "random.shuffle(total_files)\n",
        "train_index = int(len(total_files) * 0.8)\n",
        "training_files = total_files[:train_index]\n",
        "testing_files = total_files[train_index:]\n",
        "\n",
        "# Then we load these results up into 2 mini datasets\n",
        "train_data = FMRIScansData(training_files)\n",
        "test_data = FMRIScansData(testing_files)\n",
        "train_dl = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "test_dl = DataLoader(test_data, batch_size=16, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc22KLn2XNNh"
      },
      "source": [
        "# CNN Building and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlGCHymWXRQO"
      },
      "outputs": [],
      "source": [
        "# Example class, adapted from here: https://towardsdatascience.com/pytorch-step-by-step-implementation-3d-convolution-neural-network-8bf38c70e8b3\n",
        "class Example3DCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Example3DCNN, self).__init__()\n",
        "        self.conv_layer_1 = self.conv_layer_set(16, 32)\n",
        "        self.conv_layer_2 = self.conv_layer_set(32, 64)\n",
        "        self.conv_layer_3 = self.conv_layer_set(64, 128)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(128 * 7 * 7 * 9, 128 * 7 * 7)\n",
        "        self.fc2 = nn.Linear(128 * 7 * 7, 128 * 7)\n",
        "        self.fc3 = nn.Linear(128 * 7, 1)\n",
        "        self.relu = nn.LeakyReLU()\n",
        "        self.drop = nn.Dropout(p=0.15)\n",
        "    \n",
        "    def conv_layer_set(self, in_c, out_c):\n",
        "        conv_layer = nn.Sequential(\n",
        "            nn.Conv3d(in_c, out_c, kernel_size=(3, 3, 3), padding='same'),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool3d((2, 2, 2)),\n",
        "        )\n",
        "        return conv_layer\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.conv_layer_1(x)\n",
        "        out = self.conv_layer_2(out)\n",
        "        out = self.conv_layer_3(out)\n",
        "        out = self.flatten(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.drop(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc3(out)\n",
        "        out = self.relu(out)\n",
        "        out = torch.sigmoid(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SymCfcZwckwh"
      },
      "outputs": [],
      "source": [
        "# Example Hyperparameters, Loss, Optimizer, Etc\n",
        "num_epochs = 50\n",
        "learning_rate = 0.000001\n",
        "\n",
        "model = Example3DCNN()\n",
        "error = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data))\n",
        "print(len(test_data))\n",
        "print(len(train_dl))\n",
        "print(len(test_dl))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNukUXsKVahH",
        "outputId": "24f7a43e-d5d2-4dd2-f32d-3bca10344b53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "874\n",
            "219\n",
            "55\n",
            "14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85FgK6TWdNV-",
        "outputId": "03a1efbe-e900-4ffa-d6b2-eaeb001cb4f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0 Loss: 0.6931473016738892 Accuracy: 47.94520568847656 %\n",
            "Iteration: 55 Loss: 0.6931207180023193 Accuracy: 51.14155197143555 %\n",
            "Iteration: 110 Loss: 0.6930587887763977 Accuracy: 47.488582611083984 %\n",
            "Iteration: 165 Loss: 0.6931777000427246 Accuracy: 45.20547866821289 %\n",
            "Iteration: 220 Loss: 0.693226158618927 Accuracy: 53.42465591430664 %\n",
            "Iteration: 275 Loss: 0.6932247281074524 Accuracy: 43.83561706542969 %\n",
            "Iteration: 330 Loss: 0.6931149959564209 Accuracy: 51.14155197143555 %\n",
            "Iteration: 385 Loss: 0.6929469108581543 Accuracy: 50.684932708740234 %\n",
            "Iteration: 440 Loss: 0.6931084990501404 Accuracy: 52.511417388916016 %\n",
            "Iteration: 495 Loss: 0.6931896805763245 Accuracy: 49.315067291259766 %\n",
            "Iteration: 550 Loss: 0.6931754946708679 Accuracy: 54.79452133178711 %\n",
            "Iteration: 605 Loss: 0.6931832432746887 Accuracy: 48.401824951171875 %\n",
            "Iteration: 660 Loss: 0.6933375000953674 Accuracy: 48.401824951171875 %\n",
            "Iteration: 715 Loss: 0.6931467652320862 Accuracy: 49.771690368652344 %\n",
            "Iteration: 770 Loss: 0.6931688189506531 Accuracy: 50.228309631347656 %\n",
            "Iteration: 825 Loss: 0.6932253241539001 Accuracy: 50.684932708740234 %\n",
            "Iteration: 880 Loss: 0.6931857466697693 Accuracy: 48.401824951171875 %\n",
            "Iteration: 935 Loss: 0.6931005120277405 Accuracy: 51.598175048828125 %\n"
          ]
        }
      ],
      "source": [
        "# Training Model Loop\n",
        "count = 0\n",
        "loss_list = []\n",
        "iteration_list = []\n",
        "accuracy_list = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_dl):\n",
        "        labels = torch.unsqueeze(labels,-1).float()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = error(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if count % 50 == 0:\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for test_images, test_labels in test_dl:\n",
        "                outputs = model(test_images)\n",
        "                predicted = (outputs > 0.5) * 1.0\n",
        "                total += len(test_labels)\n",
        "                correct += (predicted.flatten() == test_labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct / float(total)\n",
        "            loss_list += [loss]\n",
        "            iteration_list += [count]\n",
        "            accuracy_list += [accuracy]\n",
        "\n",
        "        if count % len(train_dl) == 0:\n",
        "            print(f'Iteration: {count} Loss: {loss} Accuracy: {accuracy} %')\n",
        "        \n",
        "        count += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MaHKm4uHfsRz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}